{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d008754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from MelodyLSTMEmbV2 import MelodyLSTMEmb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41146472",
   "metadata": {},
   "source": [
    "# Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d29c0d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChordMelodyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, track_count, compass_count_path, X_path, y_path, window_size=10):\n",
    "        self.window_size = window_size\n",
    "        \n",
    "        print('Loading compass count')\n",
    "        self.compass_count = pd.read_csv(compass_count_path, names=['tid', 'compass_count'], nrows=track_count)\n",
    "        self.cc = self.compass_count['compass_count'].to_numpy()\n",
    "        self.cc_w = self.compass_count['compass_count'].to_numpy() - window_size\n",
    "        self.cum_cc = np.cumsum(self.cc)\n",
    "        self.cum_cc_w = np.cumsum(self.cc_w)\n",
    "        \n",
    "        self.cum_cc = np.append([0], self.cum_cc)\n",
    "        self.cum_cc_w = np.append([0], self.cum_cc_w)\n",
    "\n",
    "        \n",
    "        print('Loading X')\n",
    "        self.X = pd.read_csv(X_path, names=['n'+str(i) for i in range(36)] + ['chord', 'prev'], nrows=self.cum_cc[-1])\n",
    "        \n",
    "        print('Loading y')\n",
    "        self.y = pd.read_csv(y_path, names=['n'+str(i) for i in range(36)], nrows=self.cum_cc[-1])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.cum_cc_w[-1]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        bucket = np.searchsorted(self.cum_cc_w, idx, side='right')\n",
    "        # print(bucket)\n",
    "        delta = idx - self.cum_cc_w[bucket - 1]\n",
    "        # print(delta)\n",
    "        idx_start = self.cum_cc[bucket - 1]\n",
    "        # print(idx_start)\n",
    "        idx = idx_start + delta\n",
    "        \n",
    "        # print(idx)\n",
    "        x_data = torch.tensor(self.X.iloc[idx : idx + self.window_size].to_numpy(dtype=float))\n",
    "        y_data = torch.tensor(self.y.iloc[idx : idx + self.window_size].to_numpy(dtype=float))\n",
    "\n",
    "        return x_data.float(), y_data.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277c12b9",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20b593e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f22204eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading compass count\n",
      "Loading X\n",
      "Loading y\n"
     ]
    }
   ],
   "source": [
    "dataset = ChordMelodyDataset(100, '../data/compass_count2.csv', '../data/X2.csv', '../data/y2.csv', window_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "febadafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79180"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad10b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "556e1667",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "learning_rate = 1e-6\n",
    "\n",
    "input_size = 56 #number of features\n",
    "hidden_size = 512 #number of features in hidden state\n",
    "num_layers = 1 #number of stacked lstm layers\n",
    "\n",
    "output_size = 36 #number of output classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "227e10e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlstm = MelodyLSTMEmb(input_size, hidden_size, output_size, \n",
    "                   num_layers, device, threshold=0.6)\n",
    "mlstm = mlstm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3899c6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.AdamW(mlstm.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "050a436a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 310/310 [00:10<00:00, 30.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.68995893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for X, y in tqdm(data_loader):\n",
    "        X = X.cuda()\n",
    "        y = y.cuda()\n",
    "        outputs = mlstm.forward(X) #forward pass\n",
    "        optimizer.zero_grad() #calculate the gradient, manually setting to 0\n",
    "        \n",
    "        # obtain the loss function\n",
    "        # print(outputs.shape, y[:,-1,:].shape)\n",
    "        loss = criterion(outputs, y[:,-1,:])\n",
    "\n",
    "        loss.backward() #calculates the loss of the loss function\n",
    "\n",
    "        optimizer.step() #improve from loss, i.e backprop\n",
    "        \n",
    "    # torch.save(mlstm.state_dict(), f'../models/muse2_t10000_bce_w32/checkpoint-{epoch:02}.pth')    \n",
    "    print(\"Epoch: %d, loss: %1.8f\" % (epoch, loss.item())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07082a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [np.random.randint(0, 2) for i in range(38)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0a428bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[-1] = 32\n",
    "arr[-2] = 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cbba0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5093, 0.4831, 0.5017, 0.4992, 0.4797, 0.4928, 0.4880, 0.5115, 0.4918,\n",
       "         0.4877, 0.4880, 0.4864, 0.5137, 0.4956, 0.5151, 0.4896, 0.5145, 0.5146,\n",
       "         0.4929, 0.5073, 0.4897, 0.5129, 0.4879, 0.5013, 0.5074, 0.4981, 0.4895,\n",
       "         0.5133, 0.5073, 0.4927, 0.5127, 0.4935, 0.4887, 0.4990, 0.4839, 0.4995]],\n",
       "       device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlstm(torch.ones(1, 1, 38).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d43ad14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5103, 0.4849, 0.5011, 0.4978, 0.4800, 0.4910, 0.4901, 0.5115, 0.4924,\n",
       "         0.4878, 0.4857, 0.4864, 0.5121, 0.4940, 0.5137, 0.4883, 0.5134, 0.5154,\n",
       "         0.4927, 0.5062, 0.4882, 0.5138, 0.4881, 0.4999, 0.5078, 0.4987, 0.4889,\n",
       "         0.5118, 0.5076, 0.4907, 0.5123, 0.4917, 0.4883, 0.5004, 0.4851, 0.4988]],\n",
       "       device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlstm(torch.zeros(1, 1, 38).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ef71e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5117, 0.4851, 0.5001, 0.4986, 0.4792, 0.4919, 0.4895, 0.5087, 0.4941,\n",
       "         0.4889, 0.4875, 0.4880, 0.5125, 0.4962, 0.5123, 0.4897, 0.5154, 0.5154,\n",
       "         0.4930, 0.5073, 0.4899, 0.5121, 0.4881, 0.5003, 0.5081, 0.4990, 0.4897,\n",
       "         0.5121, 0.5093, 0.4923, 0.5116, 0.4909, 0.4880, 0.4985, 0.4861, 0.4998]],\n",
       "       device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlstm(torch.reshape(torch.tensor(arr), (1, 1, -1)).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1e8eafb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.reshape(torch.tensor(arr), (1, 1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "12cbe437",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = t[:, :, -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f26b2d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t[:, :, :-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fb96d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mlstm.state_dict(), '../models/muse2_t2000_v1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75af22fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlstm.embedding(torch.tensor([1]).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3290e3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/chords/CHORD_DICT.pickle', 'rb') as f: \n",
    "    CHORD_DICT = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd47ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/chords_reduced/CHORD_TO_EMB.pickle', 'rb') as f:\n",
    "    CHORD_TO_EMB = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375e13a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHORD_TO_EMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ced810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = mlstm.embedding.weight.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26796d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings[51]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
